
\begin{figure*}
 \centering 
    \begin{subfigure}[t]{1.3in}
        \includegraphics[width=1.3in]{images/AGE-MEDV.pdf}
        \caption{Input scatterplot}
        \label{fig:method_original}
    \end{subfigure}
    \begin{subfigure}[t]{1.5in}
  	\includegraphics[width=1.5in]{images/DIS.pdf}
	\caption{Partitioned by distance to an\\ employment center}
	 \label{fig:method_actual}
    \end{subfigure}
    \begin{subfigure}[t]{1.5in}
 	 \includegraphics[width=1.5in]{images/randCluster.pdf}
     \vspace{-0.37cm}
 	 \caption{Partitioned by random permutation}
	 \label{fig:method_random}
    \end{subfigure}
     \begin{subfigure}[t]{2.5in}
 	\includegraphics[width=2.5in]{images/hist-DIS.pdf}
	\caption{Distribution of Skewed scagnostics}
	 \label{fig:method_dist}
     \end{subfigure}
   \caption{Illustration of our method of evaluating small multiple displays. (a) The input scatterplot of interest. (b) Partitions determined by the mean distance to Boston's five employment centers. (c) Randomly permuted partitions of the data. (d) Distribution of Skewed scagnostics for the randomly permuted partitions. The overlaid blue lines are the corresponding true scores of the partitions in (b). The blue lines are outliers, indicating that they likely did not arise due to chance. Our algorithm will score the small multiple display in (b) highly.}
\end{figure*}


\section{Method}
\label{sec:method}

Our algorithm takes three inputs from the analyst:
\begin{enumerate}
\item a scatterplot which the analyst wants to partition into a small multiple display,
\item a scagnostic that measures the presence or absence of a visual pattern of interest to the analyst, and
\item a list of potential partitioning variables.
\end{enumerate}
The output is a scoring of the small multiple displays produced by each partitioning variable.

To motivate our algorithm, we first describe four intuitive criteria for effective small multiple displays. We then describe an algorithm that incorporates these criteria to automatically score potential partitioning variables. 

\subsection{Goodness-of-Split Criteria}
We hypothesize that effective small multiple displays conform to the following four criteria:
\begin{itemize}
\item \emph{Visually rich}: Effective small multiple displays should leverage the capabilities of the human visual system by conveying rich visual patterns. This visual richness is unlikely to be captured by the relatively simple summary statistics used in common analytic methods such as ANOVA.

\item \emph{Informative}: Small multiple displays should be more informative than the input visualization, allowing the analyst to deepen their understanding of the data. Small multiple displays that randomly partition the input data are not useful since they contain no more information than the original plot.

\item \emph{Well-supported}: For some data sets, particularly those with outliers or with a small number of data points, strong visual patterns can occur by chance. These spurious patterns are misleading; they appear informative, but are not. Good small multiple displays should convey robust patterns, guiding analysts to reliable results.

\item \emph{Parsimonious}: A small multiple display with many partitions can be very difficult to read and understand. All things being equal, we should favor fewer partitions.
\end{itemize}

\subsection{Algorithm}

The key insight of this paper is that these four criteria can be achieved using a simple heuristic: effective small multiple displays are those whose component plots have cognostic measures that are very unlikely to have arisen by random subsetting of the input plot. Using cognostics to evaluate the small multiple displays, instead of simple summary measures, ensures that we can find \emph{visually rich} patterns. If those cognostics are different from that of the input plot, then the small multiple is \emph{informative}. If those differences are unlikely to be due to chance, then the small multiple display is \emph{well-supported}. And if there are redundant partitioning variables, the least likely will also be the most \emph{parsimonious}. 

The key challenge is in determining the likelihood of a small multiple display's cognostic score since they do not come from a known distribution. In this section, we describe how to compute this likelihood using a \emph{randomized permutation test}~\cite{Good2000}, which is a non-parametric statistical significance test.

Given a partitioning variable to score, we first create its associated small multiple display and then evaluate the cognostic on each of its component plots.
We then randomly permute the values of the partitioning variable, which results in each data point being reassigned to a random partition. We then reevaluate the cognostic scores on this randomized small multiple display. By repeating this permutation procedure multiple times, we produce distributions of cognostic scores that arise ``by chance''.

We then compare the true cognostics to the random distributions to determine the likelihood of the true cognostics. We need to make a pdf since order statistics don't work. We want this to work on general cognostics which have unknown underlying distributions. Chebyshev's inequality can give us a (very) conservative bound on the likelihood regardless of the underlying distribution. It is inversely related to the z-score, so instead of minimizing the likelihood we can maximize the z-score.

This process tells us how unlikely each component plot of a small multiple is. To get a score for the whole small multiple, we again maximize across the plots.

Maximizing here means that we emphasize small multiple displays with at least one informative, well-supported pattern.


We then compare the true scores to the null distributions by evaluating a z-score. This gives us a normalized measure across cognostics as it focuses on the number of standard deviations away from the mean. We use the z-score and Chebyshev's inequality to judge how far the visual pattern in the true partition is from a random partition. The z-score for each component plot $i$ of the small multiple display is:
$$z_i = \frac{(X_i-\mu_i)}{\sigma_i}$$ 
where $X_i$ is the true cognostic value of the $i$-th partition and $\mu_i$ and $\sigma_i$ are the mean and standard deviation of the cognostic measures over the repeated random permutations of the $i$-th partition. We use a z-score, rather than an order statistic because it is common for the true value to fall well outside the range of the simulated null distribution.

Finally, to get a score for the whole small multiple display, we use the maximum absolute z-score across all the $k$ component plots: 
$$z = \max_{i=1}^k |z_i|$$
Using the maximum results in high scores for small multiple displays that have strong, interesting patterns in at least one component plot. This worked well in our experimentation. However, it may discount small multiple displays with weaker patterns in many or all the component plots. This is discussed more in Section~\ref{sec:discussion}. 

To demonstrate how this algorithm works, consider a dataset
collected by the U.S Census Service about housing in the area of Boston, Massachusetts~\cite{Harrison1978}. Figure~\ref{fig:method_original} shows the relationship between the median value of owner-occupied houses (in thousands of US dollars) and the proportion of such houses built prior to 1940. We see that as the proportion of older houses increases, the median value decreases. However, the distribution is skewed and an analyst may wonder if there is another variable that might reveal more about this relationship.
To do so, they can run our algorithm using Wilkinson et al.'s \emph{Skewed} scagnostic.

Our algorithm will iterate through the twelve possible partitioning variables in this data set, scoring each one. Figure~\ref{fig:method_actual} shows the small multiple display resulting from partitioning on the binned distance to an employment center, one of the variables in the data set. Notice that, compared to the original plot, the density of the top two plots (representing shorter distances to an employment center) appears substantially shifted to the right. While the bottom two plots (longer distances to an employment center) are shifted to the left. These differences will result in Skewed scagnostics that are substantially different from the original plot. 

However, it is possible that these shifts may have arisen due to random chance. Thus, our algorithm randomly permutes the values of the partitioning variable, producing the small multiple display in Figure~\ref{fig:method_random}. These plots show no sign of the change in skewness and look similar to the original plot. 
Our algorithm does this repeatedly, producing a distribution of possible random Skewed scagnostic values. In Figure~\ref{fig:method_dist} we show the result of this process with $1000$ repeated simulations. We experimented with increasing the number of simulations with limited gain in stability of the null distribution but with a greater cost to the computational performance. The black histograms show the distribution of the Skewed scagnostic for the random permutations. The blue lines show the Skewed scagnostic for the actual variable---the distance to employment center. For the top two plots, the blue line is to the right of the histogram, indicating that the skewness of these two plots is much higher than we would expect to occur by chance. The bottom two have lower skewness than we would expect by chance, but the values are inside the simulated distribution, so there's less evidence for them.

After computing z-scores for these four distributions, we use the maximum absolute z-score as the overall score for this small multiple display. This partitioning variable, distance to employment center, is the highest rated in this data set and would be recommended to the analyst. The corresponding small multiple display offers a visual explanation of the relationship between employment center locations to the neighborhoods in Boston---areas with older, lower-valued homes are close to employment centers while newer, higher-valued homes tend to be further away. The analyst can see the extent and shape of that correlation in the partitions of the display.
