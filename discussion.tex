\section{Discussion and Future Work}
\label{sec:discussion}
One weakness with our approach is that we do not correct for possible correlation between the patterns in the input visualization and partitioning variables. As a result, we may redundantly choose a small multiple display that shows a pattern that was already clearly visible in the original plot. While exposing highly correlated variables can be useful, it is likely not what the user wants in an effective small multiple display. Statistical methods for variable selection, such as ridge or lasso regression, can downweight highly correlated variables. Our approach would be improved by incorporating similar behavior. 

Another component of our approach that warrants further study is the choice of aggregation method to combine the partition z-scores and produce a score to rank a small multiple display. We experimented with the adding the z-scores over all component plots but this fails to penalize variables that result in a large number of partitions (less parsimonious). Our choice of the maximum absolute z-score across all component plots allows us to pick up partitions with patterns that are outliers compared to random partitions. However, it may discount small multiple displays with weaker patterns in many or all the component plots. Averaging the z-scores across component plots would help address that but at the cost of detecting strongly informative patterns that are different from the original plot. Future work could focus on taking such aspects of our approach that seem ad-hoc, towards a formalism like that of powerful statistical variable selection techniques.%, such as lasso regression.

One advantage of our approach is that it can easily be extended in a number of different ways. We have described our algorithm in terms of a permutation test, which ignores sampling error in the data set. This is correct in many common analytic scenarios where the entire population is in the data set. If, however, the user wanted to account for sampling error when scoring small multiple displays, they could instead use bootstrapping~\cite{Efron1994} to build the simulated null distributions. The structure of the approach would be unchanged.

Another natural extension of our method would be to handle continuous variables. Our method works in a straightforward manner on discrete partitioning variables. For continuous variables, discrete partitions can be created through disjoint binning techniques~\cite{Freedman1981,Scott2009}, or, overlapping bins (shingles)~\cite{Becker1996}. In either case, our approach can be extended to handle binning by first permuting the continuous variable and then applying the binning algorithm to partition the data.

Our work is a first step towards a general method for assigning confidence to visual patterns seen in small multiple displays, but, there is more to be done in this area. Non-parametric approaches allow us to use quality measures without a closed form distribution, which seems essential in evaluating visual patterns. However, these approaches are computationally demanding due to the need to recompute the measure on a large number of samples. In our approach we compute the scagnostics for each partition of each variable and then for the randomly permuted partitions for each variable. For a moderate sized dataset with thousands of rows, our R implementation takes about ten seconds on average to evaluate each partitioning variable. More work on computationally efficient visual measures is needed. Also, in our work with Scagnostics, we have found that they sometimes miss very obvious visual patterns. More work is needed to develop cognostics that are robust to properties such as sample size, the amount of noise in the data set, the location and scale of the axes, etc. 

Furthermore, our approach can be extended in powerful ways that merit future study. While we frame our algorithm in terms of scoring single variables, it is trivial to combine two discrete variables into a new discrete variable by crossing or nesting the levels of each variables~\cite{Wilkinson2005GG,Stolte2002}. Doing so would allow our algorithm to consider combinations of variables. 
Another common use case is creating small multiples by drilling down into aggregated data. A variation of our approach could be used to detect if potentially interesting visual information would be revealed by a change in level of detail. Visualization tools could use this to recommend a drill down or roll up dimension.

%Our method currently only considers a single partitioning (by one or more variables). 
Finally, we could extend our approach to consider sequences of partitionings. This could be used to develop a decision tree based exploratory data analysis interaction mechanism guided by our algorithm. At each decision level, we could apply our algorithm to select a partitioning variable given a single view of the data at that level. This would produce a small multiple display where each component plot could be further partitioned to reveal interesting structure. Considering the tree structure, each choice of a partitioning variable would be conditional on the other previously used variables, as in model selection methods. 

