%% \section{Introduction} %for journal use above \firstsection{..} instead

%Exploratory Data Analysis (EDA), championed by Tukey~\cite{Tukey1977}, relies heavily on visual representations in the search for informative and potentially surprising structure in data. Such analysis usually starts with an overview of the data dimensions of interest and follows a path of progressive refinement getting more focused or detailed based on the question being asked.

Understanding multidimensional data sets is a prevalent challenge in Exploratory Data Analysis~\cite{Tukey1977}. Many techniques have been proposed for visualizing multidimensional data in 2D. Perhaps the two most common techniques are
\emph{projective displays}, such as scatterplot matrices (SPLOMs), which use a set of 2D projections of the data set,
and \emph{small multiple displays} (also called collections or trellis displays)~\cite{Bertin1983, tufte1986, Becker1996}, which show 2D slices of data sets created by partitioning on one or more dimensions in the data set,

Unfortunately, as the number of dimensions in the data set grows, neither approach scales well since the number of plots that must be displayed increases quickly. This problem can be addressed by selecting a subset of the dimensions to project or condition on. However, in exploratory analysis scenarios, where the user does not know a priori which dimensions might be of interest, this can become a time-consuming exercise in trial and error as the user manually iterates through dimensions to find views that help explain their data set. 

In the context of projective displays, there has been substantial work in developing algorithms to automate this process~\cite{Seo2005,Wilkinson2005,Sips2009}.
Perhaps the most well-known is Scagnostics, introduced by John and Paul Tukey, which uses a set of metrics capturing interesting visual patterns to rank the scatterplots in a SPLOM, guiding users to potentially useful projections of their data~\cite{}.
%Automated dimensionality reduction techniques~\cite{Friedman1974,Yang2003,Sedlmair2013}, developed in statistics and machine learning, can also be used, though the resulting visualizations can be difficult to interpret since the axes, often linear combinations of dimensions, may not be meaningful to users.
However, there has been little corresponding work in the automatic selection of conditioning dimensions for small multiple displays. In this paper, we try to address this problem.

Dividing data between views, in small multiple displays, encodes the association between the subset of data observations in a partition using spatial proximity, which impacts the patterns that are visible. Consider the scatterplot shown in Figure~1(a) which shows the relationship between acceptance and graduation rates at US universities. The spike of points visible in the upper left is interesting. Conditioning on the average ACT score of admits helps explain this pattern. As shown in Figure~1(b), for universities with very high ACT scores, there is a nearly linear relationship between the acceptance rate and the graduation rate. For universities with middle ACT scores, the relationship is roughly Gaussian. While for universities with low ACT scores, the graduation rate is low regardless of the admission rate. Our goal is to devise a method that examines the dimensions in a data set and automatically recommends ones, such as the average ACT score in this example, that explain the patterns of interest in a source visualization.

Choosing conditioning variables for small multiple displays is closely related to the model selection problem in statistics. However, such approaches often use relatively simple closed form models that do not capture the richness of visual patterns in visualizations. Instead, we propose a method of selecting a dimension to condition a given data relationship by using non-parametric permutation tests to determine the significance of the resulting collection of data partitions we call a Split. Our contributions are:
\begin{itemize}
    \item A set of goodness criteria for the collection of partitions given a particular conditioning dimension.
    \item A method for quantitatively evaluating the quality of the partitions given a measure of interest. We compare the measure computed on a collection of partitions against reference distributions of the measure computed on randomly generated permutations of partitions which act as ``null partitions". 
\end{itemize}

The next section summarizes related work on visual explanations for multivariate data analysis. This is followed by a description of the method we propose and discussion of measures we use. Then we describe examples using our method to explain high-dimensional structure in a number of datasets. Finally, we draw conclusions from this research and outline future work.

